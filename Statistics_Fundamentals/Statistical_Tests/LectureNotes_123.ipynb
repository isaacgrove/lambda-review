{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7OLbevlbd_Z"
   },
   "source": [
    "# Lambda School Data Science Module 123\n",
    "\n",
    "## Introduction to Bayesian Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study, work through a Bayesian P(A|B) by hand. The drug use example below is good. Note how the denominator breaks into the total event space B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "\n",
    "Random Viz stuff\n",
    "  - [Matplotlib Error Bars](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html)\n",
    "  - [Seaborn barplot with error bars](https://seaborn.pydata.org/generated/seaborn.barplot.html)\n",
    "  - [Vertical ines to show bounds of confidence interval](https://www.simplypsychology.org/confidence-interval.jpg)\n",
    "  - [Confidence Intervals on Box Plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.boxplot.html)\n",
    "\n",
    "- [Blog post on Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/).\n",
    "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
    "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Detector! What would the Bayesian statistician say if I asked him whether the--' [roll] 'I AM A NEUTRINO DETECTOR, NOT A LABYRINTH GUARD. SERIOUSLY, DID YOUR BRAIN FALL OUT?' [roll] '... yes.'](https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png)\n",
    "\n",
    "*[XKCD 1132](https://www.xkcd.com/1132/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mz8p08BsN6p"
   },
   "source": [
    "## Bayes' Theorem and the Bayesian mindset\n",
    "\n",
    "Bayes' theorem possesses a near-mythical quality - a bit of math that somehow magically evaluates a situation. But this mythicality has more to do with its reputation and advanced applications than the actual core of it - which is actually remarkably straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa-jzYp9i8La"
   },
   "source": [
    "### The Law of Total Probability\n",
    "\n",
    "The total probability of all events in some event space $A$ is 1:\n",
    "\n",
    "$$P(A) = \\sum_n P(A_n) = 1$$\n",
    "\n",
    "The Law of Total Probability relates the marginal and conditional probabilities of two variables $A$ and $B$:\n",
    "\n",
    "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhycNr-Sbeie"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### The Law of Conditional Probability\n",
    "\n",
    "What's the probability of something conditioned on something else? To determine this let's go back to set theory and think about the intersection of sets:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "\"A given B is the A inside B, excludes the A outside B. So A-intersect-B / B\"\n",
    "\n",
    "![Visualization of set intersection](https://upload.wikimedia.org/wikipedia/commons/9/99/Venn0001.svg)\n",
    "\n",
    "Think of the overall rectangle as the whole probability space, $A$ as the left circle, $B$ as the right circle, and their intersection as the red area. Visualize the ratio described in the above formula and how it's different from just $P(A)$.\n",
    "\n",
    "Multiply both sides by $P(B)$ and you get \n",
    "\n",
    "$P(A|B)P(B) = P(A \\cap B)$ - sum over all event spaces of B to get the Law of Total Probability. Then, substituting,  \n",
    "\n",
    "$P(A) = \\sum_n P(A \\cap B_n)$.\n",
    "\n",
    "This may not seem like an improvement at first, but it shows that the probability of $A$ given $B$ is all the bits of $A$ that intersect with $B$, added together. The conditional probability is just that divided by the probability of $B$ itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hi45SXVyi_Wt"
   },
   "source": [
    "### Bayes Theorem\n",
    "\n",
    "Here it is, the seemingly magic tool:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "Notice how it's almost the Law of Conditional Probability, just with a different numerator\n",
    "\n",
    "The unconditioned probabilities are referred to as \"prior beliefs\", and the conditioned probabilities are the \"updates\"\n",
    "\n",
    "Why is this important? In the cartoon above, the Bayesian statistician draws a less absurd conclusion because their prior belief in the likelihood that the sun will go nova is extremely low. So, even when updated based on evidence from a detector that is $35/36 = 0.972$ accurate, the prior belief doesn't shift enough to change their opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bayes Theorem Iteratively (repeated testing)\n",
    "\n",
    "This example comes from [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n",
    "\n",
    "Let's apply Bayes' theorem to drug tests. You would be forgiven for thinking that a drug test that's 100% accurate for true positives (detects users) is pretty good, but what if it has a 1% false positive rate (depicting a non-user as a user)? And let's further postulate that the rate of drug use in the population at large (our prior belief) is 1/200.\n",
    "\n",
    "What is the likelihood somebody is a user given that they test positive? Some may guess it's 99%, but Bayes and our prior beliefs say otherwise...\n",
    "\n",
    "![Bayes Theorem Drug Test Example](https://wikimedia.org/api/rest_v1/media/math/render/svg/95c6524a3736c43e4bae139713f3df2392e6eda9)\n",
    "\n",
    "In other words, the likelihood that somebody is a user given they tested positive on a drug test is only 33.2% - probably much lower than you'd guess. This is why, in practice, it's important to use repeated testing to confirm. If we have the same individual who tested positive the first time take the drug test a second time then the posterior probability from our the first test becomes our new prior during the second application. What is the probability that a person is a drug user after two positive drug tests in a row?\n",
    "\n",
    "Bayes' theorem has been relevant in court cases where proper consideration of evidence was important. Whether it's a drug test, breathalyzer, pregnancy test, doctor's diagnosis, or neutrino detector, we have to take into account **both** the false positive rate and our prior probability in order to calculate the correct conditional probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "FTBBnqPQfeOD",
    "outputId": "2472aec7-7951-45a6-cb91-130d520ec7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Positive Given User 1\n",
      "Probability User 0.005\n",
      "Probability Positive Given Non-user 0.01\n",
      "Probability Non-user 0.995\n"
     ]
    }
   ],
   "source": [
    "# True Positive Rate 100%\n",
    "p_pos_user = 1\n",
    "# Prior Probability (1/200)\n",
    "p_user = 1/200\n",
    "# False Positive Rate 1%\n",
    "p_pos_nonuser = .01\n",
    "# Complement probability of p_user (1 - p_user)\n",
    "p_nonuser = 1 - p_user\n",
    "\n",
    "print('Probability Positive Given User', p_pos_user)\n",
    "print('Probability User', p_user)\n",
    "print('Probability Positive Given Non-user', p_pos_nonuser)\n",
    "print('Probability Non-user', p_nonuser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PWO3fLuho_F"
   },
   "source": [
    "![Bayes Theorem Drug Test Example](https://wikimedia.org/api/rest_v1/media/math/render/svg/95c6524a3736c43e4bae139713f3df2392e6eda9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kCfviVBxhknM",
    "outputId": "e74d963a-4d3b-4108-dfd6-f7dd32fbd722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probability - Test 1 0.33444816053511706\n"
     ]
    }
   ],
   "source": [
    "posterior_probability = (p_pos_user*p_user) / ((p_pos_user*p_user) + (p_pos_nonuser*p_nonuser))\n",
    "\n",
    "# The probabiltiy of a person who tests positive *actually* being a user:\n",
    "print(\"Posterior Probability - Test 1: \", posterior_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "va7i6L8li2cR",
    "outputId": "d989d0d5-3d24-4710-87cb-b3de3871a355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Positive Given User 1\n",
      "Probability User 0.33444816053511706\n",
      "Probability Positive Given Non-user 0.01\n",
      "Probability Non-user 0.6655518394648829\n"
     ]
    }
   ],
   "source": [
    "# True Positive Rate 100%\n",
    "p_pos_user = 1\n",
    "# Prior Probability (1/200)\n",
    "# In any subsequent applications of Bayes Theorem\n",
    "# Our new prior probability is the Posterior Probability \n",
    "# from the previous iteration\n",
    "p_user = posterior_probability\n",
    "# False Positive Rate 1%\n",
    "p_pos_nonuser = .01\n",
    "# Complement probability of p_user (1 - p_user)\n",
    "p_nonuser = 1 - p_user\n",
    "\n",
    "print('Probability Positive Given User', p_pos_user)\n",
    "print('Probability User', p_user)\n",
    "print('Probability Positive Given Non-user', p_pos_nonuser)\n",
    "print('Probability Non-user', p_nonuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RlSb3tiCjkdA",
    "outputId": "3153158a-4802-4bde-aeb4-5495e4cba12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probability - Test 2 0.9804882831650161\n"
     ]
    }
   ],
   "source": [
    "posterior_probability = (p_pos_user*p_user) / ((p_pos_user*p_user) + (p_pos_nonuser*p_nonuser))\n",
    "\n",
    "# The probabiltiy of a person who tests positive *actually* being a user:\n",
    "print(\"Posterior Probability - Test 2: \", posterior_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htI3DGvDsRJF"
   },
   "source": [
    "## Live Lecture - Deriving Bayes' Theorem, Calculating Bayesian Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke-5EqJI0Tsn"
   },
   "outputs": [],
   "source": [
    "# Use SciPy to calculate Bayesian confidence intervals\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html#scipy.stats.bayes_mvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht0Y5gUVmq1v"
   },
   "source": [
    "## Generate a Frequentist Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bpNfD1_QmtzD",
    "outputId": "e22e1355-6874-4131-f740-0f36a3408c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# I need a sample first\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "coinflips = np.random.binomial(n=1, p=.5, size=2)\n",
    "print(coinflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Ii_yASDlm9mz",
    "outputId": "27baaac6-d215-4ba0-81e8-f43a2e7a0118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, -5.853102368216048, 6.853102368216048)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequentist approach\n",
    "\n",
    "def confidence_interval(data, confidence=.95):\n",
    "  n = len(data)\n",
    "  mean = sum(data)/n\n",
    "  data = np.array(data)\n",
    "  std_err = stats.sem(data)\n",
    "  interval = std_err * stats.t.ppf((1 + confidence) / 2.0, n-1)\n",
    "  return (mean, mean-interval, mean+interval)\n",
    "\n",
    "confidence_interval(coinflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8V_IRaijnWQ9",
    "outputId": "4ab2de33-cde3-45f1-9d1e-0d40cb8ae2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean(statistic=inf, minmax=(-5.853102368216048, 6.853102368216048))\n"
     ]
    }
   ],
   "source": [
    "# Bayesian approach. Gives same confidence interval if you have a big enough sample\n",
    "\n",
    "bayesian_confidence_interval, _, _ = stats.bayes_mvs(coinflips, alpha=.95)\n",
    "\n",
    "print(bayesian_confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWgWjp3PQ3Sq"
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRgHqmYIQ9qn"
   },
   "source": [
    "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
    "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LectureNotes_DS12_123_Introduction_to_Bayesian_Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
